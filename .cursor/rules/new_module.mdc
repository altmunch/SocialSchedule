---
description: 
globs: 
alwaysApply: false
---
### **Workflow for AI-Assisted Module Implementation**

#### **Phase 1: Planning & Context Setup**
1. **Define the task with surgical precision**  
   - Write a detailed specification including:  
     - Purpose of the module  
     - Input/output requirements  
     - Dependencies (internal/external)  
     - Performance constraints (e.g., latency, memory)  
     - Security/validation rules [3][7]  
   - Example: *"Create a user authentication module with OAuth2, JWT tokens, rate limiting (100 requests/min), and audit logging."*

2. **Select the AI model**  
   - **For complex logic**: Use Claude (code accuracy) or DeepSeek (technical tasks)   
   - **For boilerplate**: ChatGPT or Gemini (fast iteration)
   - **For system design**: Use models with long-context handling (Claude 200k) 

3. **Prepare code context**  
   - Share relevant files via:  
     - File attachments (e.g., existing API schemas)  
     - Architecture diagrams (screenshot-to-code tools)  
     - Dependency lists (package.json/Pipfile excerpts)

---

#### **Phase 2: Implementation**

4. **Craft the prompt**  
   Use this template:  

   Role: Senior [Language] Developer  
   Task: Implement [module name]  
   Requirements:  
   - Must integrate with [existing components X,Y,Z]  
   - Follow [coding standard]  
   - Include [specific libraries/versions]  
   Constraints:  
   - No external API calls  
   - Max 200ms latency  
   Output Format:  
   - First: High-level design (pseudocode)  
   - Second: [Language] implementation  
   - Third: Unit test stubs  
 
   Add keywords: **production-grade**, **zero dependencies**, **type-safe** 

5. **Generate code iteratively**  
   - First pass: Request architectural overview  
   - Second pass: Generate core logic  
   - Third pass: Add error handling/logging  
   - Final pass: Optimization passes [1][6]  
   *Example command for GPT-Engineer:*  
   ```bash
   aider --model claude-3-opus --files user_auth.py requirements.txt
   ```

---

#### **Phase 3: Testing & Validation**

6. **AI-assisted quality checks**  
   - Run generated code through:  
     - **Static analysis**: `bandit -r .` (security)  
     - **Linting**: `ruff check .` (code quality)  
     - **Validation prompt**:  
       *"Identify potential race conditions in this code and suggest fixes."* [3][7]

7. **Test generation**  

   Generate pytest units tests for this module that:  
   - Cover all edge cases in [spec section 3.2]  
   - Mock [external service X]  
   - Achieve 90% coverage  

   Use Diffblue Cover or PyTest AI plugins for automation 

---

#### **Phase 4: Integration & Iteration**

8. **CI/CD integration**  
   - Add AI-generated modules via feature branch  
   - Configure CI to:  
     - Run generated tests  
     - Check for style violations  
     - Alert on performance regressions 

9. **Post-deployment monitoring**  
   - Use AI observability tools:  
     - **Sentry**: Error tracking  
     - **Prometheus**: Performance metrics  
     - **LangSmith**: Prompt effectiveness analysis 
---

### **Model-Specific Tips**  
- **ChatGPT-4o**: Best for rapid prototyping (use temperature=0.3 for consistency)
- **Claude 3.5**: Use for mission-critical code (enable "strict mode")   
- **Gemini 1.5**: Ideal when combining code with visual diagrams (multimodal)  

### **Critical Reminders**  
- Always review AI output for:  
  - License compliance (GPL contamination)  
  - Hardcoded secrets (even in comments)  
  - Proper input sanitization 
- Maintain a prompt library of verified templates 










